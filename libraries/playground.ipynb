{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webScraper import sahibindenLib\n",
    "from dataWorker import dataWorker\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from seleniumbase import Driver\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver import ActionChains\n",
    "import time, random, re\n",
    "from sys import exit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = Driver(uc=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sahibindenLib.sahibindenInit(driver)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sahibindenLib.sahibindenSearch(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_url= driver.current_url\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "titles_raw = soup.find_all(class_=\"classifiedTitle\")\n",
    "titles = []\n",
    "h_refs = []\n",
    "\n",
    "for tt in titles_raw:\n",
    "    print(\"----------------------------------------------\")\n",
    "    titles.append(tt.getText().strip())\n",
    "    h_refs.append(current_url + tt.get(\"href\"))\n",
    "\n",
    "    print(\"current_url: \" + tt.get(\"href\"))\n",
    "\n",
    "    print(\"Title: \" + tt.getText().strip())\n",
    "    print(\"Link: \" + current_url + tt.get(\"href\"))\n",
    "    print(\"Link V2: \" + \"sahibinden.com\" + tt.get(\"href\"))\n",
    "    print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def dataToPandas(title, link, square_meters, rooms, price, date, district):\n",
    "        data = {\n",
    "                \"title\": [title],\n",
    "                \"link\": [link],\n",
    "                \"square_meters\": [square_meters],\n",
    "                \"rooms\": [rooms],\n",
    "                \"price\": [price],\n",
    "                \"date\": [date],\n",
    "                \"district\": [district]\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(data, index=[0])  # Pass index=[0] when creating the DataFrame\n",
    "        df.to_csv(\"data.csv\", mode=\"a\", header=False)\n",
    "\n",
    "def dataCSVControl(title, link, square_meters, rooms, price, date, district):\n",
    "        df = pd.read_csv(\"data.csv\")\n",
    "        df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "        df = df.drop_duplicates(subset=['link'], keep='first')\n",
    "        df = df.reset_index(drop=True)\n",
    "        df.to_csv(\"data.csv\")\n",
    "\n",
    "        if link not in df[\"link\"].values:\n",
    "                return True\n",
    "        else:\n",
    "                return False\n",
    "\n",
    "\n",
    "def dataWorkerStart(title, link, square_meters, rooms, price, date, district):\n",
    "       \n",
    "        try:\n",
    "                df = pd.read_csv(\"data.csv\")\n",
    "        except:\n",
    "                df = pd.DataFrame(columns=[\"title\", \"link\", \"square_meters\", \"rooms\", \"price\", \"date\", \"district\"])\n",
    "                df.to_csv(\"data.csv\")\n",
    "\n",
    "        bool_CSV_Control = dataCSVControl(title, link, square_meters, rooms, price, date, district)\n",
    "        if bool_CSV_Control:\n",
    "                dataToPandas(title, link, square_meters, rooms, price, date, district)\n",
    "                dataWorker.dataWorker(title, link, square_meters, rooms, price, date, district)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def sahibindenPostRecorder(driver):\n",
    "\n",
    "    current_url= driver.current_url\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    titles_raw = soup.find_all(class_=\"classifiedTitle\")\n",
    "    specs_raw = soup.find_all(class_=\"searchResultsAttributeValue\")\n",
    "    price_raw = soup.find_all(class_=\"classified-price-container\")\n",
    "    dates_raw = soup.find_all(class_=\"searchResultsDateValue\")\n",
    "    districts_raw = soup.find_all(class_=\"searchResultsLocationValue\")\n",
    "\n",
    "    titles = []\n",
    "    h_refs = []\n",
    "\n",
    "    specs = [sp.getText().strip() for sp in specs_raw]\n",
    "    rooms = specs[1::2]\n",
    "    square_meters = specs[0::2]\n",
    "    prices = [pr.getText().strip() for pr in price_raw]\n",
    "    dates = [dt.getText().strip().replace(\"\\n\\n\", \" \") for dt in dates_raw]\n",
    "    districts = [BeautifulSoup(str(ds), 'html.parser').get_text(separator='-').replace('/n', '-').replace(' / ', '-').strip() for ds in districts_raw]\n",
    "\n",
    "\n",
    "    for tt in titles_raw:\n",
    "        titles.append(tt.getText().strip())\n",
    "        h_refs.append(\"https://www.sahibinden.com\" + tt.get(\"href\"))\n",
    "\n",
    "    for i in range(len(titles)):\n",
    "        inputs = driver.find_elements(By.CSS_SELECTOR, \"input[type='text']\")\n",
    "        print(\"Title: \" + titles[i])\n",
    "        print(\"Link: \" + h_refs[i])\n",
    "        print(\"Square Meters: \" + square_meters[i])\n",
    "        print(\"Rooms: \" + rooms[i])\n",
    "        print(\"Price: \" + prices[i])\n",
    "        print(\"Date: \" + dates[i])\n",
    "        print(\"District: \" + districts[i])\n",
    "        print(\"--------------------------------------------------\" + \"\\n\")\n",
    "    \n",
    "        dataWorkerStart(titles[i], h_refs[i], square_meters[i], rooms[i], prices[i], dates[i], districts[i])\n",
    "        \n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sahibindenPostRecorder(driver)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstoneEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
